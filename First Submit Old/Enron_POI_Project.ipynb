{
 "metadata": {
  "name": "",
  "signature": "sha256:46bccabbd8e8573247cb717a438eceea4c18f2ec1fb29a36d72c4a466eb553cd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "#Fang Lu\n",
      "#Enron poi_id.py progression and testing\n",
      "#\n",
      "\n",
      "import sys\n",
      "import pickle\n",
      "sys.path.append(\"../tools/\")\n",
      "\n",
      "from feature_format import featureFormat, targetFeatureSplit\n",
      "from tester import test_classifier, dump_classifier_and_data\n",
      "import pprint\n",
      "\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "from sklearn.tree import DecisionTreeClassifier as DTC\n",
      "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
      "from sklearn.ensemble import RandomForestClassifier as RFC\n",
      "\n",
      "### Task 1: Select what features you'll use.\n",
      "### features_list is a list of strings, each of which is a feature name.\n",
      "### The first feature must be \"poi\".\n",
      "#features_list = ['poi','salary','exercised_stock_options'] #With DTC gives .32 and .36 precision and recall\n",
      "#features_list = ['poi','salary', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options','long_term_incentive', 'restricted_stock']\n",
      "#features_list = ['poi','salary','exercised_stock_options', 'bonus','total_stock_value']# With DTC and PCA default gives precision .43 and recall .39\n",
      "#features_list = ['poi','salary','exercised_stock_options', 'bonus','total_stock_value']# With tuned DTC(15) and PCA gives .53 and .49\n",
      "#feature_list= ['poi','exercised_stock_options','shared_receipt_with_poi','to_poi_ratio','expenses']#With tuned DTC(min_samples = 16) gives .48 and .49\n",
      "\n",
      "#Features Selected for final analysis, removed all features with over 50% missing values\n",
      "features_list = ['poi',\n",
      "                 #'salary',\n",
      "                 'exercised_stock_options',\n",
      "                 #'bonus',\n",
      "                 #'total_stock_value',\n",
      "                 'shared_receipt_with_poi',\n",
      "                 #'from_poi_ratio',\n",
      "                 'to_poi_ratio',\n",
      "                 'expenses',\n",
      "                 #'restricted_stock',\n",
      "                 #'total_payments',\n",
      "                 ]\n",
      "#Function to get dataset statistics/Exploratory\n",
      "def getDataSetStat(data_dict, *args):\n",
      "    poiCount = 0\n",
      "    poilist = []\n",
      "    for i in data_dict:\n",
      "        if data_dict[i]['poi'] == True:\n",
      "            poilist.append(i)\n",
      "            poiCount += 1\n",
      "    flist = []\n",
      "    featureCount = len(data_dict['HANNON KEVIN P'])\n",
      "    for k in data_dict['HANNON KEVIN P']:\n",
      "        flist.append(k)\n",
      "    \n",
      "    fmissing = {}\n",
      "    for l in flist:\n",
      "        count = 0\n",
      "        for i in data_dict:\n",
      "            if data_dict[i][l] == 'NaN':\n",
      "                count += 1\n",
      "        fmissing[l] = count\n",
      "    setDict = {}\n",
      "    setDict['poiCount']= poiCount\n",
      "    setDict['poilist'] = poilist\n",
      "    setDict['flist'] = flist\n",
      "    setDict['fmissing'] = fmissing\n",
      "    setDict['featureCount'] = featureCount\n",
      "    for i in args:\n",
      "        if i == 0:\n",
      "            pprint.pprint(setDict)\n",
      "        else:\n",
      "            return setDict\n",
      "\n",
      "### Load the dictionary containing the dataset\n",
      "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
      "\n",
      "getDataSetStat(data_dict, 0)\n",
      "\n",
      "### Task 2: Remove outliers\n",
      "### Removed the obvious outlier of TOTAL from the dataset.\n",
      "data_dict.pop('TOTAL', 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'featureCount': 21,\n",
        " 'flist': ['salary',\n",
        "           'to_messages',\n",
        "           'deferral_payments',\n",
        "           'total_payments',\n",
        "           'exercised_stock_options',\n",
        "           'bonus',\n",
        "           'restricted_stock',\n",
        "           'shared_receipt_with_poi',\n",
        "           'restricted_stock_deferred',\n",
        "           'total_stock_value',\n",
        "           'expenses',\n",
        "           'loan_advances',\n",
        "           'from_messages',\n",
        "           'other',\n",
        "           'from_this_person_to_poi',\n",
        "           'poi',\n",
        "           'director_fees',\n",
        "           'deferred_income',\n",
        "           'long_term_incentive',\n",
        "           'email_address',\n",
        "           'from_poi_to_this_person'],\n",
        " 'fmissing': {'bonus': 64,\n",
        "              'deferral_payments': 107,\n",
        "              'deferred_income': 97,\n",
        "              'director_fees': 129,\n",
        "              'email_address': 35,\n",
        "              'exercised_stock_options': 44,\n",
        "              'expenses': 51,\n",
        "              'from_messages': 60,\n",
        "              'from_poi_to_this_person': 60,\n",
        "              'from_this_person_to_poi': 60,\n",
        "              'loan_advances': 142,\n",
        "              'long_term_incentive': 80,\n",
        "              'other': 53,\n",
        "              'poi': 0,\n",
        "              'restricted_stock': 36,\n",
        "              'restricted_stock_deferred': 128,\n",
        "              'salary': 51,\n",
        "              'shared_receipt_with_poi': 60,\n",
        "              'to_messages': 60,\n",
        "              'total_payments': 21,\n",
        "              'total_stock_value': 20},\n",
        " 'poiCount': 18,\n",
        " 'poilist': ['HANNON KEVIN P',\n",
        "             'COLWELL WESLEY',\n",
        "             'RIEKER PAULA H',\n",
        "             'KOPPER MICHAEL J',\n",
        "             'SHELBY REX',\n",
        "             'DELAINEY DAVID W',\n",
        "             'LAY KENNETH L',\n",
        "             'BOWEN JR RAYMOND M',\n",
        "             'BELDEN TIMOTHY N',\n",
        "             'FASTOW ANDREW S',\n",
        "             'CALGER CHRISTOPHER F',\n",
        "             'RICE KENNETH D',\n",
        "             'SKILLING JEFFREY K',\n",
        "             'YEAGER F SCOTT',\n",
        "             'HIRKO JOSEPH',\n",
        "             'KOENIG MARK E',\n",
        "             'CAUSEY RICHARD A',\n",
        "             'GLISAN JR BEN F']}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "{'bonus': 97343619,\n",
        " 'deferral_payments': 32083396,\n",
        " 'deferred_income': -27992891,\n",
        " 'director_fees': 1398517,\n",
        " 'email_address': 'NaN',\n",
        " 'exercised_stock_options': 311764000,\n",
        " 'expenses': 5235198,\n",
        " 'from_messages': 'NaN',\n",
        " 'from_poi_to_this_person': 'NaN',\n",
        " 'from_this_person_to_poi': 'NaN',\n",
        " 'loan_advances': 83925000,\n",
        " 'long_term_incentive': 48521928,\n",
        " 'other': 42667589,\n",
        " 'poi': False,\n",
        " 'restricted_stock': 130322299,\n",
        " 'restricted_stock_deferred': -7576788,\n",
        " 'salary': 26704229,\n",
        " 'shared_receipt_with_poi': 'NaN',\n",
        " 'to_messages': 'NaN',\n",
        " 'total_payments': 309886585,\n",
        " 'total_stock_value': 434509511}"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 3: Create new feature(s)\n",
      "#Created the ratio features from and to poi feature divided by the total the total recieved and sent messages\n",
      "for i in data_dict:\n",
      "    #avoid divide by zero\n",
      "    if data_dict[i]['from_messages'] != 'NaN' and data_dict[i]['from_messages'] != 0:\n",
      "        data_dict[i]['to_poi_ratio'] = float(data_dict[i]['from_this_person_to_poi'])/data_dict[i]['from_messages']\n",
      "    else:\n",
      "        data_dict[i]['to_poi_ratio']='NaN'\n",
      "    \n",
      "    if data_dict[i]['to_messages'] != 'NaN' and data_dict[i]['to_messages'] != 0:\n",
      "        data_dict[i]['from_poi_ratio'] = float(data_dict[i]['from_poi_to_this_person'])/data_dict[i]['to_messages']\n",
      "    else:\n",
      "        data_dict[i]['from_poi_ratio']='NaN'\n",
      "    \n",
      "    if data_dict[i]['to_messages'] != 'NaN' and data_dict[i]['to_messages'] != 0:\n",
      "        data_dict[i]['shared_poi_ratio'] = float(data_dict[i]['shared_receipt_with_poi'])/data_dict[i]['to_messages']\n",
      "    else:\n",
      "        data_dict[i]['shared_poi_ratio']='NaN'\n",
      "### Store to my_dataset for easy export below.\n",
      "my_dataset = data_dict\n",
      "\n",
      "### Extract features and labels from dataset for local testing\n",
      "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
      "labels, features = targetFeatureSplit(data)\n",
      "\n",
      "from sklearn import cross_validation\n",
      "\n",
      "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.4, random_state=None)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 4: Try a varity of classifiers\n",
      "### Please name your classifier clf for easy export below.\n",
      "### Note that if you want to do PCA or other multi-stage operations,\n",
      "### you'll need to use Pipelines. For more info:\n",
      "### http://scikit-learn.org/stable/modules/pipeline.html\n",
      "\n",
      "def classifiertest():\n",
      "    clfvalid = GaussianNB()\n",
      "    clfvalid.fit(features_train, labels_train)\n",
      "    score = clfvalid.score(features_test, labels_test)\n",
      "    precision, recall = getRelevance(clfvalid)\n",
      "    print \"GuassianNB:-----\"\n",
      "    print \"Accuracy: \", score\n",
      "    print \"Precision: \",precision, \" Recall: \", recall\n",
      "    \n",
      "    clfvalid = DTC()\n",
      "    clfvalid.fit(features_train, labels_train)\n",
      "    score = clfvalid.score(features_test, labels_test)\n",
      "    precision, recall = getRelevance(clfvalid)\n",
      "    print \"DTC:-----\"\n",
      "    print \"Importance: \", clfvalid.feature_importances_\n",
      "    print \"Accuracy: \", score\n",
      "    print \"Precision: \",precision, \" Recall: \", recall\n",
      "    \n",
      "    clfvalid = RFC()\n",
      "    clfvalid.fit(features_train, labels_train)\n",
      "    score = clfvalid.score(features_test, labels_test)\n",
      "    precision, recall = getRelevance(clfvalid)\n",
      "    print \"RFC:-----\"\n",
      "    print \"Accuracy: \", score\n",
      "    print \"Precision: \",precision, \" Recall: \", recall\n",
      "    \n",
      "    clfvalid = ABC(DTC())\n",
      "    clfvalid.fit(features_train, labels_train)\n",
      "    score = clfvalid.score(features_test, labels_test)\n",
      "    precision, recall = getRelevance(clfvalid)\n",
      "    print \"ABC:-----\"\n",
      "    print \"Accuracy: \", score\n",
      "    print \"Precision: \",precision, \" Recall: \", recall\n",
      "    \n",
      "    estimators = [('reduce_dim', PCA()), ('svm', DTC())]\n",
      "    clfvalid = Pipeline(estimators)\n",
      "    clfvalid.fit(features_train, labels_train)\n",
      "    score = clfvalid.score(features_test, labels_test)\n",
      "    precision, recall = getRelevance(clfvalid)\n",
      "    print \"PCA-DTC:-----\"\n",
      "    print \"Accuracy: \", score\n",
      "    print \"Precision: \",precision, \" Recall: \", recall\n",
      "    \n",
      "    estimators = estimators = [('scaling', MinMaxScaler()),('dtc', SVC())]\n",
      "    clfvalid = Pipeline(estimators)\n",
      "    clfvalid.fit(features_train, labels_train)\n",
      "    score = clfvalid.score(features_test, labels_test)\n",
      "    precision, recall = getRelevance(clfvalid)\n",
      "    print \"MinMax-SVC:-----\"\n",
      "    print \"Accuracy: \", score\n",
      "    print \"Precision: \",precision, \" Recall: \", recall\n",
      "    \n",
      "    \n",
      "\n",
      "def getRelevance(clfvalid):\n",
      "    true_negatives = 0\n",
      "    false_negatives = 0\n",
      "    true_positives = 0\n",
      "    false_positives = 0\n",
      "\n",
      "    predictions = clfvalid.predict(features_test)\n",
      "    for prediction, truth in zip(predictions, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives+.001)\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives+.001)\n",
      "    return precision, recall\n",
      "\n",
      "classifiertest()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GuassianNB:-----\n",
        "Accuracy:  0.890909090909\n",
        "Precision:  0.333277787035  Recall:  0.499875031242\n",
        "DTC:-----\n",
        "Importance:  [ 0.40803006  0.07196162  0.21936145  0.30064687]\n",
        "Accuracy:  0.890909090909\n",
        "Precision:  0.249937515621  Recall:  0.249937515621\n",
        "RFC:-----\n",
        "Accuracy:  0.890909090909\n",
        "Precision:  0.0  Recall:  0.0\n",
        "ABC:-----\n",
        "Accuracy:  0.890909090909\n",
        "Precision:  0.249937515621  Recall:  0.249937515621\n",
        "PCA-DTC:-----\n",
        "Accuracy:  0.8\n",
        "Precision:  0.181801654395  Recall:  0.499875031242\n",
        "MinMax-SVC:-----\n",
        "Accuracy:  0.927272727273\n",
        "Precision:  0.0  Recall:  0.0\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##-------------------\n",
      "##Below are tests ran with tester.py with K-fold cross-validation\n",
      "##-------------------\n",
      "\n",
      "#estimators = [('reduce_dim', PCA()), ('svm', SVC())]\n",
      "#estimators = [('reduce_dim', MinMaxScaler()), ('svm', SVC())]\n",
      "#clf = Pipeline(estimators)\n",
      "#clf = SVC(kernel = 'linear',gamma = .01)\n",
      "#clf= SVC()\n",
      "clf = DTC(min_samples_split=16)\n",
      "#clf = ABC(DTC())\n",
      "#clf = DTC()\n",
      "#clf=RFC()\n",
      "#clf = RFC(n_estimators=20, min_samples_split=16)\n",
      "#estimators = [('reduce_dim', PCA()), ('dtc', DTC(min_samples_split=16))]\n",
      "#estimators = [('scaling', MinMaxScaler()),('reduce_dim', PCA()), ('dtc', SVC())]\n",
      "#estimators = [('scaling', StandardScaler()),('reduce_dim', PCA(n_components=2)), ('dtc', DTC(min_samples_split=16))]\n",
      "#clf = Pipeline(estimators)\n",
      "#estimators = [('reduce_dim', PCA()), ('dtc', ABC(DTC(),n_estimators=600))]\n",
      "#clf = Pipeline(estimators)\n",
      "#estimators = [('reduce_dim', PCA()), ('gnb', GaussianNB())]\n",
      "#clf = Pipeline(estimators)\n",
      "\n",
      "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
      "### using our testing script.\n",
      "### Because of the small size of the dataset, the script uses stratified\n",
      "### shuffle split cross validation. For more info: \n",
      "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
      "\n",
      "def iterPipe(num1,num2):\n",
      "    for i in range(num1,num2+1):\n",
      "        #estimators = [('scaling', StandardScaler()),('reduce_dim', PCA()), ('dtc', DTC(min_samples_split=i*2))]\n",
      "        #estimators = [('reduce_dim', PCA(n_components=2)), ('dtc', DTC(min_samples_split=i))]\n",
      "        #clfIter = Pipeline(estimators)\n",
      "        #clfIter.set_params(reduce_dim__n_components=3)\n",
      "        clfIter = DTC(min_samples_split=i)\n",
      "        test_classifier(clfIter, my_dataset, features_list)\n",
      "        \n",
      "#get DTC feature importance \n",
      "def getDTCimportance():\n",
      "    clf2 = DTC(min_samples_split=16)\n",
      "    clf2.fit(features, labels)\n",
      "    imp = clf2.feature_importances_\n",
      "    f_importance = {}\n",
      "    c = 0\n",
      "    for i in features_list[1:]:\n",
      "        f_importance[i]=imp[c]\n",
      "        c +=1\n",
      "    #pprint.pprint(f_importance)\n",
      "    return f_importance\n",
      "\n",
      "\n",
      "#iterPipe(2,20)\n",
      "#iterPipe(14,18)\n",
      "f_importance = getDTCimportance()\n",
      "\n",
      "#Final Classifier and Result\n",
      "clf = DTC(min_samples_split=16)\n",
      "test_classifier(clf, my_dataset, features_list)\n",
      "\n",
      "### Dump your classifier, dataset, and features_list so \n",
      "### anyone can run/check your results.\n",
      "\n",
      "dump_classifier_and_data(clf, my_dataset, features_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=16,\n",
        "            random_state=None, splitter='best')\n",
        "\tAccuracy: 0.85257\tPrecision: 0.48431\tRecall: 0.49400\tF1: 0.48911\tF2: 0.49203\n",
        "\tTotal predictions: 14000\tTrue positives:  988\tFalse positives: 1052\tFalse negatives: 1012\tTrue negatives: 10948\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}