{
 "metadata": {
  "name": "",
  "signature": "sha256:df5ed0c101f74523d0694c320313730c29f9a7443a5342bc45cb51ee99f56853"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "#Fang Lu\n",
      "#Enron poi_id.py progression and testing\n",
      "#\n",
      "\n",
      "import sys\n",
      "import pickle\n",
      "sys.path.append(\"../tools/\")\n",
      "from scipy.stats import pearsonr as Pearson\n",
      "from scipy.stats import pointbiserialr as Biserial\n",
      "import numpy as np\n",
      "import operator\n",
      "\n",
      "from feature_format import featureFormat, targetFeatureSplit\n",
      "from tester import test_classifier, dump_classifier_and_data\n",
      "import pprint\n",
      "\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "from sklearn.feature_selection import SelectKBest, f_regression, chi2\n",
      "from sklearn.tree import DecisionTreeClassifier as DTC\n",
      "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
      "from sklearn.ensemble import RandomForestClassifier as RFC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.metrics import precision_score\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "\n",
      "### Task 1: Select what features you'll use.\n",
      "### features_list is a list of strings, each of which is a feature name.\n",
      "### The first feature must be \"poi\".\n",
      "\n",
      "#Feature selections performed by removing non-correlated features and performing exhaustive search on remaining\n",
      "\n",
      "#Features Selected Originally DTC(min_samples_split=15) Precision = 0.48, Recall = 0.49\n",
      "#features_list = ['poi','exercised_stock_options','shared_receipt_with_poi','to_poi_ratio','expenses']\n",
      "\n",
      "#Final Features List \n",
      "features_list = ['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
      "\n",
      "#Function to get dataset statistics/Exploratory Calculates NaN\n",
      "def getDataSetStat(data_dict, *args):\n",
      "    poiCount = 0\n",
      "    poilist = []\n",
      "    for i in data_dict:\n",
      "        if data_dict[i]['poi'] == True:\n",
      "            poilist.append(i)\n",
      "            poiCount += 1\n",
      "    flist = []\n",
      "    featureCount = len(data_dict['HANNON KEVIN P'])\n",
      "    for k in data_dict['HANNON KEVIN P']:\n",
      "        flist.append(k)\n",
      "    \n",
      "    fmissing = {}\n",
      "    for l in flist:\n",
      "        count = 0\n",
      "        for i in data_dict:\n",
      "            if data_dict[i][l] == 'NaN':\n",
      "                count += 1\n",
      "        fmissing[l] = count\n",
      "    setDict = {}\n",
      "    setDict['poiCount']= poiCount\n",
      "    setDict['poilist'] = poilist\n",
      "    setDict['flist'] = flist\n",
      "    setDict['fmissing'] = fmissing\n",
      "    setDict['featureCount'] = featureCount\n",
      "    for i in args:\n",
      "        if i == 0:\n",
      "            pprint.pprint(setDict)\n",
      "        else:\n",
      "            return setDict\n",
      "\n",
      "### Load the dictionary containing the dataset\n",
      "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
      "\n",
      "getDataSetStat(data_dict, 0)\n",
      "\n",
      "### Task 2: Remove outliers\n",
      "### Removed the obvious outlier of TOTAL from the dataset.\n",
      "data_dict.pop('TOTAL', 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'featureCount': 21,\n",
        " 'flist': ['salary',\n",
        "           'to_messages',\n",
        "           'deferral_payments',\n",
        "           'total_payments',\n",
        "           'exercised_stock_options',\n",
        "           'bonus',\n",
        "           'restricted_stock',\n",
        "           'shared_receipt_with_poi',\n",
        "           'restricted_stock_deferred',\n",
        "           'total_stock_value',\n",
        "           'expenses',\n",
        "           'loan_advances',\n",
        "           'from_messages',\n",
        "           'other',\n",
        "           'from_this_person_to_poi',\n",
        "           'poi',\n",
        "           'director_fees',\n",
        "           'deferred_income',\n",
        "           'long_term_incentive',\n",
        "           'email_address',\n",
        "           'from_poi_to_this_person'],\n",
        " 'fmissing': {'bonus': 64,\n",
        "              'deferral_payments': 107,\n",
        "              'deferred_income': 97,\n",
        "              'director_fees': 129,\n",
        "              'email_address': 35,\n",
        "              'exercised_stock_options': 44,\n",
        "              'expenses': 51,\n",
        "              'from_messages': 60,\n",
        "              'from_poi_to_this_person': 60,\n",
        "              'from_this_person_to_poi': 60,\n",
        "              'loan_advances': 142,\n",
        "              'long_term_incentive': 80,\n",
        "              'other': 53,\n",
        "              'poi': 0,\n",
        "              'restricted_stock': 36,\n",
        "              'restricted_stock_deferred': 128,\n",
        "              'salary': 51,\n",
        "              'shared_receipt_with_poi': 60,\n",
        "              'to_messages': 60,\n",
        "              'total_payments': 21,\n",
        "              'total_stock_value': 20},\n",
        " 'poiCount': 18,\n",
        " 'poilist': ['HANNON KEVIN P',\n",
        "             'COLWELL WESLEY',\n",
        "             'RIEKER PAULA H',\n",
        "             'KOPPER MICHAEL J',\n",
        "             'SHELBY REX',\n",
        "             'DELAINEY DAVID W',\n",
        "             'LAY KENNETH L',\n",
        "             'BOWEN JR RAYMOND M',\n",
        "             'BELDEN TIMOTHY N',\n",
        "             'FASTOW ANDREW S',\n",
        "             'CALGER CHRISTOPHER F',\n",
        "             'RICE KENNETH D',\n",
        "             'SKILLING JEFFREY K',\n",
        "             'YEAGER F SCOTT',\n",
        "             'HIRKO JOSEPH',\n",
        "             'KOENIG MARK E',\n",
        "             'CAUSEY RICHARD A',\n",
        "             'GLISAN JR BEN F']}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "{'bonus': 97343619,\n",
        " 'deferral_payments': 32083396,\n",
        " 'deferred_income': -27992891,\n",
        " 'director_fees': 1398517,\n",
        " 'email_address': 'NaN',\n",
        " 'exercised_stock_options': 311764000,\n",
        " 'expenses': 5235198,\n",
        " 'from_messages': 'NaN',\n",
        " 'from_poi_to_this_person': 'NaN',\n",
        " 'from_this_person_to_poi': 'NaN',\n",
        " 'loan_advances': 83925000,\n",
        " 'long_term_incentive': 48521928,\n",
        " 'other': 42667589,\n",
        " 'poi': False,\n",
        " 'restricted_stock': 130322299,\n",
        " 'restricted_stock_deferred': -7576788,\n",
        " 'salary': 26704229,\n",
        " 'shared_receipt_with_poi': 'NaN',\n",
        " 'to_messages': 'NaN',\n",
        " 'total_payments': 309886585,\n",
        " 'total_stock_value': 434509511}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 3: Create new feature(s)\n",
      "#Created the ratio features from and to poi feature divided by the total the total recieved and sent messages\n",
      "for i in data_dict:\n",
      "    #avoid divide by zero\n",
      "    if data_dict[i]['from_messages'] != 'NaN' and data_dict[i]['from_messages'] != 0:\n",
      "        data_dict[i]['to_poi_ratio'] = float(data_dict[i]['from_this_person_to_poi'])/data_dict[i]['from_messages']\n",
      "    else:\n",
      "        data_dict[i]['to_poi_ratio']='NaN'\n",
      "    \n",
      "    if data_dict[i]['to_messages'] != 'NaN' and data_dict[i]['to_messages'] != 0:\n",
      "        data_dict[i]['from_poi_ratio'] = float(data_dict[i]['from_poi_to_this_person'])/data_dict[i]['to_messages']\n",
      "    else:\n",
      "        data_dict[i]['from_poi_ratio']='NaN'\n",
      "    \n",
      "    if data_dict[i]['to_messages'] != 'NaN' and data_dict[i]['to_messages'] != 0:\n",
      "        data_dict[i]['shared_poi_ratio'] = float(data_dict[i]['shared_receipt_with_poi'])/data_dict[i]['to_messages']\n",
      "    else:\n",
      "        data_dict[i]['shared_poi_ratio']='NaN'\n",
      "### Store to my_dataset for easy export below.\n",
      "my_dataset = data_dict\n",
      "\n",
      "### Extract features and labels from dataset for local testing\n",
      "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
      "labels, features = targetFeatureSplit(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 4: Try a varity of classifiers\n",
      "### Please name your classifier clf for easy export below.\n",
      "### Note that if you want to do PCA or other multi-stage operations,\n",
      "### you'll need to use Pipelines. For more info:\n",
      "### http://scikit-learn.org/stable/modules/pipeline.html\n",
      "\n",
      "\n",
      "#Feature Selection and Classifier Selection are Combined in Task 4\n",
      "\n",
      "##--First Get Correlations--##\n",
      "\n",
      "#Creates X and Y array for correlation given the raw data from featureFormat\n",
      "def getXY(corrData):\n",
      "    x = []\n",
      "    y = []\n",
      "    for item in corrData:\n",
      "        y.append( item[0] )\n",
      "        x.append( item[1] )\n",
      "    return y, x\n",
      "            \n",
      "#Calculates the Point Biserial Correlation (Pearson) of Features to 'poi'\n",
      "def corrPOI(myData):\n",
      "    flist = []\n",
      "    for k in myData['HANNON KEVIN P']:\n",
      "        flist.append(k)\n",
      "    flist.remove('email_address')\n",
      "    \n",
      "    pbsDict = {}\n",
      "    for i in flist:\n",
      "        corrList = ['poi', i]      \n",
      "        pbsCorr = getCorr(myData, corrList)\n",
      "        pbsDict[i] = pbsCorr\n",
      "\n",
      "    correlations = pbsDict\n",
      "    #Prints the Sorted Correlations Starting with the Highest Correlation\n",
      "    for w in sorted(correlations, key=correlations.get, reverse=True):\n",
      "        print w, correlations[w][0], correlations[w][1]\n",
      "            \n",
      "    return pbsDict\n",
      "\n",
      "#Performs Pearsons Correlation test (same as PointBiserial Mathematically)\n",
      "def getCorr(myData, corrList):\n",
      "    corrData = featureFormat(myData, corrList, remove_all_zeroes = False, sort_keys = True)\n",
      "    y, x = getXY(corrData)\n",
      "    \n",
      "    #Using pearsons makes getCorr more robust for feature correlation   \n",
      "    return Pearson(y,x)\n",
      "\n",
      "#Performs correlations on between all Features Results\n",
      "def corrAll(myData):\n",
      "    flist = []\n",
      "    for k in myData['HANNON KEVIN P']:\n",
      "        flist.append(k)\n",
      "    flist.remove('email_address')\n",
      "    \n",
      "    #Creates a dictionary to store all the correlations between features\n",
      "    corrDict = {}\n",
      "\n",
      "    for i in flist:\n",
      "        corrDict[i] = {}\n",
      "        for j in flist:\n",
      "            corrList = [i,j]\n",
      "            pbsCorr = getCorr(myData, corrList)\n",
      "            corrDict[i][j] = pbsCorr\n",
      "            \n",
      "    #filters out highly correlated feature pairs      \n",
      "    uncorr = {}\n",
      "    for i in corrDict:\n",
      "        uncorr[i]={}\n",
      "        for j in corrDict[i]:\n",
      "            if abs(corrDict[i][j][0]) <= 0.2:\n",
      "                uncorr[i][j]=corrDict[i][j]\n",
      "    \n",
      "    return corrDict, uncorr\n",
      "\n",
      "#Utility function for reading correlations\n",
      "def readCorr(corrDict, f1, f2=None):\n",
      "    print '--------'\n",
      "    if f2:       \n",
      "        print 'r and p-values for:',f1,'and',f2, corrDict['shared_receipt_with_poi']['to_poi_ratio']\n",
      "    else:\n",
      "        print 'All Correlations with ',f1\n",
      "        pprint.pprint(corrDict[f1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "poiCorr = corrPOI(my_dataset)\n",
      "allCorr, unCorr = corrAll(my_dataset)\n",
      "\n",
      "#Examples on How to Access the Feature Correlation Results\n",
      "featureOne = 'to_poi_ratio'\n",
      "featureTwo = 'exercised_stock_options'\n",
      "\n",
      "readCorr(allCorr, featureOne, featureTwo)\n",
      "readCorr(allCorr, featureOne)\n",
      "readCorr(poiCorr, featureOne)\n",
      "readCorr(unCorr, featureTwo)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "poi 1.0 0.0\n",
        "exercised_stock_options 0.388240932495 1.39844379624e-06\n",
        "total_stock_value 0.384127328764 1.84442641518e-06\n",
        "bonus 0.360261879419 8.54824089976e-06\n",
        "salary 0.341365272148 2.64644859937e-05\n",
        "to_poi_ratio 0.324876732525 6.69501897034e-05\n",
        "long_term_incentive 0.258300532053 0.00170779873759\n",
        "shared_poi_ratio 0.249484578579 0.00247654528533\n",
        "restricted_stock 0.249352479819 0.00249013485014\n",
        "total_payments 0.242922426024 0.00323908741099\n",
        "shared_receipt_with_poi 0.242105064233 0.00334758801368\n",
        "loan_advances 0.220405154039 0.00772404163029\n",
        "expenses 0.206580138412 0.0126677439102\n",
        "from_poi_to_this_person 0.191549478161 0.0209984606978\n",
        "other 0.170152903716 0.0407441413689\n",
        "from_poi_ratio 0.150050517384 0.0716363587097\n",
        "from_this_person_to_poi 0.130318717414 0.11820944997\n",
        "to_messages 0.110006241805 0.187775953065\n",
        "restricted_stock_deferred -0.0212293452401 0.799919572768\n",
        "from_messages -0.0333024028484 0.690885571544\n",
        "deferral_payments -0.0382665261468 0.647693141785\n",
        "director_fees -0.120000684544 0.150520996067\n",
        "deferred_income -0.275364467008 0.000801787624478\n",
        "--------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "r and p-values for: to_poi_ratio and exercised_stock_options (0.29145709877994069, 0.00037543758797555155)\n",
        "--------\n",
        "All Correlations with  to_poi_ratio\n",
        "{'bonus': (0.26551407013934969, 0.0012480008293847778),\n",
        " 'deferral_payments': (0.13549384129663852, 0.10417466946667124),\n",
        " 'deferred_income': (-0.15495034933370541, 0.062750367778246857),\n",
        " 'director_fees': (-0.18251306415375831, 0.028005006578534553),\n",
        " 'exercised_stock_options': (0.11116581742066009, 0.183137115292688),\n",
        " 'expenses': (0.073776125664531289, 0.3778331722988042),\n",
        " 'from_messages': (-0.056162824816195653, 0.50224187459255942),\n",
        " 'from_poi_ratio': (0.48986738681563358, 4.0161170717938875e-10),\n",
        " 'from_poi_to_this_person': (0.26050277271176719, 0.0015532744696187708),\n",
        " 'from_this_person_to_poi': (0.085562745583923891, 0.30617908288600931),\n",
        " 'loan_advances': (0.15282624222747879, 0.066485034917165911),\n",
        " 'long_term_incentive': (0.1625435483298224, 0.050777718118666992),\n",
        " 'other': (0.15343952596188798, 0.065388597752063876),\n",
        " 'poi': (0.32487673252513133, 6.6950189703414558e-05),\n",
        " 'restricted_stock': (0.11786638256615448, 0.15796711934392896),\n",
        " 'restricted_stock_deferred': (-0.02615400787182029, 0.75484020681147113),\n",
        " 'salary': (0.30947718179383038, 0.00015200813287637071),\n",
        " 'shared_poi_ratio': (0.6841053989486634, 2.4418476880965229e-21),\n",
        " 'shared_receipt_with_poi': (0.29145709877994069, 0.00037543758797555155),\n",
        " 'to_messages': (0.12595766222953109, 0.13113971558477377),\n",
        " 'to_poi_ratio': (1.0, 0.0),\n",
        " 'total_payments': (0.1893186359215541, 0.02257020653162561),\n",
        " 'total_stock_value': (0.12608903247027214, 0.13073497630955902)}\n",
        "--------\n",
        "All Correlations with  to_poi_ratio\n",
        "(0.32487673252513133, 6.6950189703414558e-05)\n",
        "--------\n",
        "All Correlations with  exercised_stock_options\n",
        "{'deferral_payments': (0.11874850398360141, 0.15485679520930706),\n",
        " 'director_fees': (-0.11505640188399531, 0.16818715165055415),\n",
        " 'expenses': (0.12463051044692124, 0.13528263015935332),\n",
        " 'from_messages': (-0.022549355892408907, 0.78776475945933089),\n",
        " 'from_poi_ratio': (0.026412945060278591, 0.75249119934064679),\n",
        " 'from_poi_to_this_person': (0.12733039735905344, 0.12695764186192432),\n",
        " 'from_this_person_to_poi': (0.0035945599735588947, 0.96577348265623442),\n",
        " 'restricted_stock_deferred': (-0.0020105076081681395, 0.9808524461776299),\n",
        " 'shared_poi_ratio': (0.067482386446271622, 0.41996478616943278),\n",
        " 'shared_receipt_with_poi': (0.12826911071806144, 0.12415748124817773),\n",
        " 'to_messages': (0.087432150287701779, 0.29569295582360822),\n",
        " 'to_poi_ratio': (0.11116581742066009, 0.183137115292688)}\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PCA Analysis for insight into the features\n",
      "\n",
      "def pcaGet(myData):\n",
      "    #Builds the feature_list for all of the features\n",
      "    flist = []\n",
      "    for k in myData['HANNON KEVIN P']:\n",
      "        flist.append(k)\n",
      "    flist.remove('email_address')\n",
      "    flist.remove('poi')\n",
      "    flist.insert(0, 'poi')\n",
      "    \n",
      "    #pprint.pprint(flist)\n",
      "    \n",
      "    #Obtain the features in array format from featureFormat and split out 'poi'\n",
      "    pcaData = featureFormat(myData, flist , remove_all_zeroes = False, sort_keys = True)\n",
      "    labels, features = targetFeatureSplit(pcaData)  \n",
      "    \n",
      "    #Run PCA showing the first 5 components, change n_components to see more\n",
      "    pca = PCA(n_components=5, whiten=False)\n",
      "    pca.fit(features)\n",
      "    print '-----No StandardScalling-----'\n",
      "    pprint.pprint(pca.explained_variance_ratio_) \n",
      "    #uncomment to see breakdown of PC contributions by features\n",
      "    #pprint.pprint(pca.components_)    \n",
      "    var = pca.explained_variance_ratio_\n",
      "    print 'Total Variance Captured: ', sum(var[0:5])\n",
      "    #newFeatures = pca.transform(features)\n",
      "    \n",
      "    #With StandardScaler\n",
      "    stdScaler = StandardScaler()\n",
      "    scaledFeatures = stdScaler.fit_transform(features)\n",
      "    pcaStd = PCA(n_components=22, whiten=True)\n",
      "    pcaStd.fit(scaledFeatures)\n",
      "    \n",
      "    print '-----With StandardScalling-----'\n",
      "    pprint.pprint(pcaStd.explained_variance_ratio_) \n",
      "    varStd = pcaStd.explained_variance_ratio_\n",
      "    numPC = 14\n",
      "    print 'Total Variance Captured: ', sum(varStd[0:14])\n",
      "    #pprint.pprint(pcaStd.components_)\n",
      "    newFeatures = pcaStd.transform(features)\n",
      "\n",
      "    \n",
      "    return var, labels, newFeatures, features\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "variance, lab, newFeat, oldFeat = pcaGet(my_dataset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-----No StandardScalling-----\n",
        "array([ 0.80541619,  0.14738483,  0.01642436,  0.01473028,  0.00747514])\n",
        "Total Variance Captured:  0.99143079896\n",
        "-----With StandardScalling-----\n",
        "array([  3.06682307e-01,   1.59748900e-01,   9.16950414e-02,\n",
        "         6.58986785e-02,   6.37298060e-02,   4.37623682e-02,\n",
        "         3.85499548e-02,   3.55278215e-02,   3.45243761e-02,\n",
        "         3.04578595e-02,   2.80559746e-02,   2.09893239e-02,\n",
        "         1.91172409e-02,   1.66016044e-02,   1.32581098e-02,\n",
        "         1.03798897e-02,   9.05905128e-03,   6.61788589e-03,\n",
        "         3.77121181e-03,   1.54631887e-03,   2.62554427e-05,\n",
        "         2.00375674e-08])\n",
        "Total Variance Captured:  0.955341257088\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Cross-Validation and Exhaustive Search\n",
      "\n",
      "\n",
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "#Modified test_classifier from tester.py, to be able to reduce the folds and use different random_state\n",
      "#This modified classifier also allows for preloading of labels and features, thus can perform preprocessing such as PCA\n",
      "def test_classifier_mod(clf, dataset, feature_list, folds = 1000, preload = False, lab = [], feat = [], printYes = True):\n",
      "    \n",
      "    #Used to run preloaded feature set as in for PCA Analysis\n",
      "    if preload:\n",
      "        #print 'in preload'\n",
      "        labels = lab\n",
      "        features = feat\n",
      "    else:\n",
      "        data = featureFormat(dataset, feature_list, sort_keys = True)\n",
      "        labels, features = targetFeatureSplit(data)\n",
      "    \n",
      "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
      "    #cv = StratifiedShuffleSplit(labels, folds, random_state = None)\n",
      "    true_negatives = 0\n",
      "    false_negatives = 0\n",
      "    true_positives = 0\n",
      "    false_positives = 0\n",
      "    for train_idx, test_idx in cv: \n",
      "        features_train = []\n",
      "        features_test  = []\n",
      "        labels_train   = []\n",
      "        labels_test    = []\n",
      "        for ii in train_idx:\n",
      "            features_train.append( features[ii] )\n",
      "            labels_train.append( labels[ii] )\n",
      "        for jj in test_idx:\n",
      "            features_test.append( features[jj] )\n",
      "            labels_test.append( labels[jj] )\n",
      "        \n",
      "        ### fit the classifier using training set, and test on test set\n",
      "        clf.fit(features_train, labels_train)\n",
      "        predictions = clf.predict(features_test)\n",
      "        for prediction, truth in zip(predictions, labels_test):\n",
      "            if prediction == 0 and truth == 0:\n",
      "                true_negatives += 1\n",
      "            elif prediction == 0 and truth == 1:\n",
      "                false_negatives += 1\n",
      "            elif prediction == 1 and truth == 0:\n",
      "                false_positives += 1\n",
      "            else:\n",
      "                true_positives += 1\n",
      "    try:\n",
      "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "        accuracy = 1.0*(true_positives + true_negatives)/(total_predictions)\n",
      "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "        \n",
      "        #Can turn off Printing\n",
      "        if printYes:\n",
      "            print clf\n",
      "            print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "            print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "            print \"\"\n",
      "        \n",
      "        #returns Precision and Recall for easier access to results\n",
      "        return precision, recall\n",
      "    except:\n",
      "        print \"Got a divide by zero when trying out:\", clf\n",
      "        precision = 0\n",
      "        recall = 0\n",
      "        return precision, recall\n",
      "\n",
      "#Test Multiple Classifiers \n",
      "def test_classifiers(testOption, feat_list, use_pca_features = False):\n",
      "    print 'Feature List: ',feat_list\n",
      "\n",
      "    if testOption == 0: \n",
      "        clfvalid = GaussianNB()\n",
      "        print \"GuassianNB:-----\"\n",
      "    elif testOption == 1:\n",
      "        clfvalid = DTC(min_samples_split=2)\n",
      "        print \"DTC:-----\"\n",
      "    elif testOption == 2:\n",
      "        clfvalid = RFC()\n",
      "        print \"RFC:-----\"\n",
      "    elif testOption == 3:\n",
      "        clfvalid = ABC(DTC())\n",
      "        print \"AdaBoostC:-----\"\n",
      "    elif testOption == 4:\n",
      "        estimators = [('reduce_dim', PCA()), ('dtc', DTC())]\n",
      "        clfvalid = Pipeline(estimators)\n",
      "        print \"PCA-DTC:-----\"\n",
      "    elif testOption == 5:\n",
      "        estimators = [('reduce_dim', PCA(n_components=2)), ('dtc', DTC(min_samples_split=17))]\n",
      "        clfvalid = Pipeline(estimators)\n",
      "        print \"Tuned-PCA-DTC:-----\"\n",
      "    \n",
      "    #Option to Use PCA features\n",
      "    if use_pca_features:\n",
      "        pre, re = test_classifier_mod(clfvalid, my_dataset, feat_list, preload = True, lab=lab, feat = newFeat)\n",
      "    else:\n",
      "        pre, re = test_classifier_mod(clfvalid, my_dataset, feat_list, printYes = True)\n",
      "    \n",
      "    return pre, re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Sample Call to test_classifiers\n",
      "f_minPlusSharedR = ['poi',\n",
      "                'exercised_stock_options',\n",
      "                'to_poi_ratio',\n",
      "                'shared_receipt_with_poi']\n",
      "\n",
      "p, r = test_classifiers(4, f_minPlusSharedR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature List:  ['poi', 'exercised_stock_options', 'to_poi_ratio', 'shared_receipt_with_poi']\n",
        "PCA-DTC:-----\n",
        "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=None, whiten=False)), ('dtc', DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'))])"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.84800\tPrecision: 0.55308\tRecall: 0.45850\tF1: 0.50137\tF2: 0.47474\n",
        "\tTotal predictions: 12000\tTrue positives:  917\tFalse positives:  741\tFalse negatives: 1083\tTrue negatives: 9259\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Feature Testing functions using K-Fold cross validation and different feature sets\n",
      "def featureTest(use_ftest = False, ftest = []):\n",
      "    \n",
      "    #All Features\n",
      "    f_all = ['poi',\n",
      "             'exercised_stock_options',\n",
      "             'total_stock_value', \n",
      "             'bonus', \n",
      "             'salary', \n",
      "             'to_poi_ratio', \n",
      "             'deferred_income',\n",
      "             'long_term_incentive', \n",
      "             'shared_poi_ratio', \n",
      "             'restricted_stock', \n",
      "             'total_payments', \n",
      "             'shared_receipt_with_poi', \n",
      "             'loan_advances', \n",
      "             'expenses', \n",
      "             'from_poi_to_this_person', \n",
      "             'other', \n",
      "             'from_poi_ratio', \n",
      "             'from_this_person_to_poi', \n",
      "             'to_messages', \n",
      "             'restricted_stock_deferred', \n",
      "             'from_messages', \n",
      "             'deferral_payments',\n",
      "             'director_fees']\n",
      "    \n",
      "    #13 Most Correlated Features that are Significant ~98% Confidence\n",
      "    f_correlated = ['poi',\n",
      "             'exercised_stock_options',\n",
      "             'total_stock_value', \n",
      "             'bonus', \n",
      "             'salary', \n",
      "             'to_poi_ratio',\n",
      "             'deferred_income',\n",
      "             'long_term_incentive', \n",
      "             'shared_poi_ratio', \n",
      "             'restricted_stock', \n",
      "             'total_payments', \n",
      "             'shared_receipt_with_poi', \n",
      "             'loan_advances', \n",
      "             'expenses']\n",
      "    \n",
      "    #Financial Only\n",
      "    f_financial = ['poi',\n",
      "             'exercised_stock_options',\n",
      "             'total_stock_value', \n",
      "             'bonus', \n",
      "             'salary', \n",
      "             'long_term_incentive', \n",
      "             'restricted_stock', \n",
      "             'total_payments', \n",
      "             'loan_advances', \n",
      "             'expenses']\n",
      "    \n",
      "    \n",
      "    #E-mail Only\n",
      "    f_email_only = ['poi',\n",
      "             'to_poi_ratio', \n",
      "             'shared_poi_ratio', \n",
      "             'shared_receipt_with_poi']\n",
      "    \n",
      "    f_email_2 = ['poi',\n",
      "             'to_poi_ratio', \n",
      "             'shared_poi_ratio', \n",
      "             'shared_receipt_with_poi']\n",
      "    \n",
      "    f_email_1 = ['poi',\n",
      "             'to_poi_ratio']\n",
      "    \n",
      "    f_email_original = ['poi',\n",
      "             'shared_receipt_with_poi', \n",
      "             'from_poi_to_this_person', \n",
      "             'from_this_person_to_poi', \n",
      "             'to_messages', \n",
      "             'from_messages']\n",
      "    \n",
      "    f_email_created = ['poi',\n",
      "             'to_poi_ratio', \n",
      "             'shared_poi_ratio',  \n",
      "             'from_poi_ratio']\n",
      "    \n",
      "    #Misc Tests, By Selecting Top Correlations for Financial and E-mail\n",
      "    f_min = ['poi',\n",
      "             'exercised_stock_options',\n",
      "             'to_poi_ratio']\n",
      "    \n",
      "    f_minPlus = ['poi',\n",
      "                'exercised_stock_options',\n",
      "                'to_poi_ratio',\n",
      "                'bonus',\n",
      "                'expenses']\n",
      "    \n",
      "    f_minPlusExp = ['poi',\n",
      "                'exercised_stock_options',\n",
      "                'to_poi_ratio',\n",
      "                'expenses']\n",
      "    \n",
      "    f_minPlusSharedR = ['poi',\n",
      "                'exercised_stock_options',\n",
      "                'to_poi_ratio',\n",
      "                'shared_poi_ratio']\n",
      "    \n",
      "    f_minPlusShared = ['poi',\n",
      "                'exercised_stock_options',\n",
      "                'to_poi_ratio',\n",
      "                'shared_receipt_with_poi']\n",
      "    \n",
      "    #Random Tests By Hand\n",
      "    f_test = ['poi',\n",
      "                'exercised_stock_options',\n",
      "                'shared_receipt_with_poi']\n",
      "    \n",
      "    f_c_selected = ['poi',\n",
      "             'exercised_stock_options', \n",
      "             'bonus',\n",
      "             'to_poi_ratio',\n",
      "             'deferred_income',\n",
      "             'shared_receipt_with_poi',  \n",
      "             'expenses']\n",
      "    \n",
      "    f_c_selected_2 = ['poi',\n",
      "             'exercised_stock_options', \n",
      "             'bonus',\n",
      "             'shared_receipt_with_poi']\n",
      "    \n",
      "    prStr = []\n",
      "    pre = 0\n",
      "    re = 0\n",
      "    if use_ftest:\n",
      "        for i in range(6):\n",
      "            pre, re = test_classifiers(i, ftest)\n",
      "            prStr.append(pre)\n",
      "            prStr.append(re)\n",
      "    else:\n",
      "        for i in range(6):\n",
      "            pre, re = test_classifiers(i, f_c_selected_2)\n",
      "            prStr.append(pre)\n",
      "            prStr.append(re)\n",
      "            #classifer_stratified_test(i, features_list, use_pca_features = True)\n",
      "\n",
      "    print prStr\n",
      "    return prStr\n",
      "\n",
      "#Exhaustive feature testing after selection down to 6 variables\n",
      "#function tests feature sets created by removing features individually\n",
      "#Produces an array of arrays of the precision and recall scores for the 6 classifiers\n",
      "def featIter(num=0):\n",
      "    f_c = ['poi',\n",
      "             'exercised_stock_options',\n",
      "             'total_stock_value', \n",
      "             'bonus', \n",
      "             'salary', \n",
      "             'to_poi_ratio',\n",
      "             'deferred_income',\n",
      "             'long_term_incentive', \n",
      "             'shared_poi_ratio', \n",
      "             'restricted_stock', \n",
      "             'total_payments', \n",
      "             'shared_receipt_with_poi', \n",
      "             'loan_advances', \n",
      "             'expenses']\n",
      "    f_c_selected = ['poi',\n",
      "             'exercised_stock_options', \n",
      "             'bonus',\n",
      "             'to_poi_ratio',\n",
      "             'deferred_income',\n",
      "             'shared_receipt_with_poi',  \n",
      "             'expenses']\n",
      "    f_c_selected_2 = ['poi',\n",
      "             'exercised_stock_options', \n",
      "             'bonus',\n",
      "             'shared_receipt_with_poi']\n",
      "    #Expense down to 3 variables\n",
      "    f_sans_expense = ['poi', 'exercised_stock_options', 'bonus', 'to_poi_ratio', 'deferred_income', 'shared_receipt_with_poi']\n",
      "    \n",
      "    f_sans_expense_def_inc = ['poi', 'exercised_stock_options', 'bonus', 'to_poi_ratio', 'shared_receipt_with_poi']\n",
      "    \n",
      "    #Deferred_income down to 3 variables\n",
      "    f_sans_def_inc = ['poi', 'exercised_stock_options', 'bonus', 'to_poi_ratio', 'shared_receipt_with_poi', 'expenses']\n",
      "    \n",
      "    f_sans_def_inc_tpr = ['poi', 'exercised_stock_options', 'bonus', 'shared_receipt_with_poi', 'expenses']\n",
      "    \n",
      "    #Bonus down to 3 variables\n",
      "    f_sans_bonus = ['poi', 'exercised_stock_options', 'to_poi_ratio', 'deferred_income', 'shared_receipt_with_poi', 'expenses']\n",
      "    \n",
      "    f_sans_bonus_shared = ['poi', 'exercised_stock_options', 'to_poi_ratio', 'deferred_income', 'expenses']\n",
      "\n",
      "    \n",
      "    #Final\n",
      "    f_final = ['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
      "    \n",
      "    #For performing a reverse test, by adding to Final features and see if the model improves\n",
      "    f_remaining1 = ['total_stock_value', \n",
      "             'bonus', \n",
      "             'salary', \n",
      "             'to_poi_ratio', \n",
      "             'long_term_incentive', \n",
      "             'shared_poi_ratio', \n",
      "             'restricted_stock', \n",
      "             'total_payments', \n",
      "             'shared_receipt_with_poi', \n",
      "             'loan_advances',  \n",
      "             'from_poi_to_this_person', \n",
      "             'other', \n",
      "             'from_poi_ratio', \n",
      "             'from_this_person_to_poi', \n",
      "             'to_messages', \n",
      "             'restricted_stock_deferred', \n",
      "             'from_messages', \n",
      "             'deferral_payments',\n",
      "             'director_fees']\n",
      "    \n",
      "    f_remaining = []\n",
      "    \n",
      "    pr_Arr = []\n",
      "    #Removes \n",
      "    topRemove = False\n",
      "    #Test Final Feature Set by Addition of remaining features individually\n",
      "    final = True\n",
      "    \n",
      "    \n",
      "    if topRemove:\n",
      "        for i in range(num):\n",
      "            f_c_selected \n",
      "            f_c_selected.pop(1)\n",
      "            pr = featureTest(use_ftest = True, ftest = f_c_selected)\n",
      "            pr_Arr.append(pr)\n",
      "    elif final:\n",
      "        f_c_selected = f_final\n",
      "        pr = featureTest(use_ftest = True, ftest = f_c_selected)\n",
      "        pr_Arr.append(pr)\n",
      "    \n",
      "        for i in range(len(f_remaining)):\n",
      "            f_c_selected = f_final+[f_remaining[i]]\n",
      "            pr = featureTest(use_ftest = True, ftest = f_c_selected)\n",
      "            pr_Arr.append(pr)\n",
      "    else:\n",
      "        #Change f_c_selected with desired feature list to perform removal of individual features\n",
      "        f_c_selected = f_sans_bonus_shared\n",
      "        pr = featureTest(use_ftest = True, ftest = f_c_selected)\n",
      "        pr_Arr.append(pr)\n",
      "        num = len(f_c_selected)-1\n",
      "        for i in range(num):\n",
      "            ftest = f_c_selected[0:(num-i)] + f_c_selected[(num-i+1):]\n",
      "            pr = featureTest(use_ftest = True, ftest = ftest)\n",
      "            pr_Arr.append(pr)\n",
      "            print ftest\n",
      "        \n",
      "        \n",
      "    print 'Tests Done...'\n",
      "    return pr_Arr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pr_Arr = featIter()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
        "GuassianNB:-----\n",
        "GaussianNB()"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.86871\tPrecision: 0.56221\tRecall: 0.36600\tF1: 0.44337\tF2: 0.39346\n",
        "\tTotal predictions: 14000\tTrue positives:  732\tFalse positives:  570\tFalse negatives: 1268\tTrue negatives: 11430\n",
        "\n",
        "['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
        "DTC:-----\n",
        "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.86086\tPrecision: 0.51308\tRecall: 0.51000\tF1: 0.51153\tF2: 0.51061\n",
        "\tTotal predictions: 14000\tTrue positives: 1020\tFalse positives:  968\tFalse negatives:  980\tTrue negatives: 11032\n",
        "\n",
        "['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
        "RFC:-----\n",
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.85407\tPrecision: 0.47655\tRecall: 0.21850\tF1: 0.29962\tF2: 0.24504\n",
        "\tTotal predictions: 14000\tTrue positives:  437\tFalse positives:  480\tFalse negatives: 1563\tTrue negatives: 11520\n",
        "\n",
        "['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
        "AdaBoostC:-----\n",
        "AdaBoostClassifier(algorithm='SAMME.R',\n",
        "          base_estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'),\n",
        "          learning_rate=1.0, n_estimators=50, random_state=None)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.85843\tPrecision: 0.50453\tRecall: 0.50100\tF1: 0.50276\tF2: 0.50170\n",
        "\tTotal predictions: 14000\tTrue positives: 1002\tFalse positives:  984\tFalse negatives:  998\tTrue negatives: 11016\n",
        "\n",
        "['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
        "PCA-DTC:-----\n",
        "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=None, whiten=False)), ('dtc', DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'))])"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.83636\tPrecision: 0.41885\tRecall: 0.37550\tF1: 0.39599\tF2: 0.38344\n",
        "\tTotal predictions: 14000\tTrue positives:  751\tFalse positives: 1042\tFalse negatives: 1249\tTrue negatives: 10958\n",
        "\n",
        "['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
        "Tuned-PCA-DTC:-----\n",
        "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=2, whiten=False)), ('dtc', DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=17,\n",
        "            random_state=None, splitter='best'))])"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.83807\tPrecision: 0.40998\tRecall: 0.30400\tF1: 0.34912\tF2: 0.32057\n",
        "\tTotal predictions: 14000\tTrue positives:  608\tFalse positives:  875\tFalse negatives: 1392\tTrue negatives: 11125\n",
        "\n",
        "[0.5622119815668203, 0.366, 0.5130784708249497, 0.51, 0.4765539803707743, 0.2185, 0.5045317220543807, 0.501, 0.41885108756274403, 0.3755, 0.40997977073499664, 0.304]\n",
        "Tests Done...\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Parameter Tuning GridSearchCV and Manual\n",
      "\n",
      "#GridSearchCV for Classifier Parameter tuning\n",
      "\n",
      "#PCA-Decision Tree GridSeachCV\n",
      "def pcadtcGrid():\n",
      "    #features_list = ['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
      "    features_list = ['poi',\n",
      "                     'exercised_stock_options',\n",
      "                     'to_poi_ratio',\n",
      "                     'shared_receipt_with_poi']\n",
      "\n",
      "    estimators = [('reduce_dim', PCA()), ('dtc', DTC())]\n",
      "    pipe = Pipeline(estimators)\n",
      "\n",
      "    param_grid = dict(reduce_dim__n_components=[1,2],\n",
      "                      dtc__min_samples_split=np.arange(2,20))\n",
      "    #print param_grid\n",
      "\n",
      "    d = featureFormat(my_dataset, features_list, sort_keys = True)\n",
      "\n",
      "    y, X = targetFeatureSplit(d)\n",
      "\n",
      "    grid_search = GridSearchCV(pipe, param_grid=param_grid, verbose=False)\n",
      "    grid_search.fit(X, y)\n",
      "    print '----PCA-DTC-GridSeachCV----'\n",
      "    print(grid_search.best_estimator_)\n",
      "\n",
      "#Decision Tree GridSearchCV \n",
      "def dtcGrid():\n",
      "    \n",
      "    features_list = ['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
      "\n",
      "    estimators = [('dtc', DTC())]\n",
      "    pipe = Pipeline(estimators)\n",
      "\n",
      "    param_grid = dict(dtc__min_samples_split=np.arange(2,36))\n",
      "    d = featureFormat(my_dataset, features_list, sort_keys = True)\n",
      "\n",
      "    y, X = targetFeatureSplit(d)\n",
      "\n",
      "    grid_search = GridSearchCV(pipe, param_grid=param_grid, verbose=False)\n",
      "    grid_search.fit(X, y)\n",
      "    print '----DTC-GridSeachCV----'\n",
      "    print(grid_search.best_estimator_)\n",
      "    \n",
      "#Manual Parameter Tuning using DTC\n",
      "def paramTune(start,end):\n",
      "    scores= {}\n",
      "    for i in range(start,end+1):\n",
      "        #Uncomment to test\n",
      "        \n",
      "        #Parameter Tune Pipelined classifiers\n",
      "        #estimators = [('scaling', StandardScaler()),('reduce_dim', PCA()), ('dtc', DTC(min_samples_split=i*2))]\n",
      "        #estimators = [('reduce_dim', PCA(n_components=2)), ('dtc', DTC(min_samples_split=i))]\n",
      "        #clfIter = Pipeline(estimators)\n",
      "        #clfIter.set_params(reduce_dim__n_components=3)\n",
      "        \n",
      "        #Paramter Tune for simple classifiers\n",
      "        #clfIter = DTC(min_samples_leaf=i, min_samples_split=3)\n",
      "        #clfIter = DTC(min_samples_split=3, max_depth = i)\n",
      "        #test_classifier(clfIter, my_dataset, features_list)\n",
      "        \n",
      "        clfIter = DTC(min_samples_split=i)\n",
      "        \n",
      "        p,r = test_classifier_mod(clfIter, my_dataset, features_list, printYes = False)\n",
      "        scores[i]=p+r\n",
      "        \n",
      "    print '----ParamTune----'    \n",
      "    print 'Max Precision and Recall Combined Score: ', max(scores.values())\n",
      "    print 'Tuned Parameter: ', max(scores.iteritems(), key=operator.itemgetter(1))[0] \n",
      "    \n",
      "    return scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Call GridSearchCV functions\n",
      "pcadtcGrid()\n",
      "dtcGrid()\n",
      "\n",
      "#Change the features to tune different feature set\n",
      "#features_list = ['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
      "start = 2\n",
      "end = 36\n",
      "scoreDict = paramTune(start,end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "----PCA-DTC-GridSeachCV----\n",
        "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=2, whiten=False)), ('dtc', DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=5,\n",
        "            random_state=None, splitter='best'))])\n",
        "----DTC-GridSeachCV----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Pipeline(steps=[('dtc', DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=12,\n",
        "            random_state=None, splitter='best'))])\n",
        "----ParamTune----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Max Precision and Recall Combined Score:  1.02121537623\n",
        "Tuned Parameter:  3\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Function to get feature importance for DTC\n",
      "def getDTCimportance(features_list):\n",
      "    \n",
      "    #features_list = ['poi', 'exercised_stock_options', 'deferred_income', 'expenses']\n",
      "    \n",
      "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
      "    labels, features = targetFeatureSplit(data)\n",
      "    \n",
      "    clf2 = DTC(min_samples_split=16)\n",
      "    clf2.fit(features, labels)\n",
      "    imp = clf2.feature_importances_\n",
      "    f_importance = {}\n",
      "    c = 0\n",
      "    for i in features_list[1:]:\n",
      "        f_importance[i]=imp[c]\n",
      "        c +=1\n",
      "    #pprint.pprint(f_importance)\n",
      "    return f_importance\n",
      "\n",
      "f_importance = getDTCimportance(features_list)\n",
      "print '----------'\n",
      "print 'Feature Importances: ', f_importance\n",
      "\n",
      "#Final Classifier and Result\n",
      "clf = DTC(min_samples_split=3)\n",
      "test_classifier(clf, my_dataset, features_list)\n",
      "\n",
      "### Dump your classifier, dataset, and features_list so \n",
      "### anyone can run/check your results.\n",
      "\n",
      "dump_classifier_and_data(clf, my_dataset, features_list)\n",
      "print 'Pickle Files Generated...'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "----------\n",
        "Feature Importances:  {'exercised_stock_options': 0.33242521584234697, 'deferred_income': 0.24507671495289665, 'expenses': 0.42249806920475635}\n",
        "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=3,\n",
        "            random_state=None, splitter='best')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.86379\tPrecision: 0.52496\tRecall: 0.48900\tF1: 0.50634\tF2: 0.49579\n",
        "\tTotal predictions: 14000\tTrue positives:  978\tFalse positives:  885\tFalse negatives: 1022\tTrue negatives: 11115\n",
        "\n",
        "Pickle Files Generated...\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}